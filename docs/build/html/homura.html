

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>homura package &mdash; homura  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="homura.callbacks package" href="homura.callbacks.html" />
    <link rel="prev" title="Indices and tables" href="index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> homura
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">homura package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#subpackages">Subpackages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="homura.callbacks.html">homura.callbacks package</a></li>
<li class="toctree-l3"><a class="reference internal" href="homura.metrics.html">homura.metrics package</a></li>
<li class="toctree-l3"><a class="reference internal" href="homura.modules.html">homura.modules package</a></li>
<li class="toctree-l3"><a class="reference internal" href="homura.utils.html">homura.utils package</a></li>
<li class="toctree-l3"><a class="reference internal" href="homura.vision.html">homura.vision package</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-homura.debug">homura.debug module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-homura.liblog">homura.liblog module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-homura.lr_scheduler">homura.lr_scheduler module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-homura.optim">homura.optim module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-homura.reporters">homura.reporters module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-homura.trainers">homura.trainers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-homura">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="homura.callbacks.html">homura.callbacks package</a></li>
<li class="toctree-l1"><a class="reference internal" href="homura.metrics.html">homura.metrics package</a></li>
<li class="toctree-l1"><a class="reference internal" href="homura.modules.html">homura.modules package</a></li>
<li class="toctree-l1"><a class="reference internal" href="homura.modules.functional.html">homura.modules.functional package</a></li>
<li class="toctree-l1"><a class="reference internal" href="homura.utils.html">homura.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="homura.vision.html">homura.vision package</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">homura</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>homura package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/homura.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="homura-package">
<h1>homura package<a class="headerlink" href="#homura-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="homura.callbacks.html">homura.callbacks package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="homura.callbacks.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="homura.callbacks.html#module-homura.callbacks.base">homura.callbacks.base module</a></li>
<li class="toctree-l2"><a class="reference internal" href="homura.callbacks.html#module-homura.callbacks.metrics">homura.callbacks.metrics module</a></li>
<li class="toctree-l2"><a class="reference internal" href="homura.callbacks.html#module-homura.callbacks.saver">homura.callbacks.saver module</a></li>
<li class="toctree-l2"><a class="reference internal" href="homura.callbacks.html#module-homura.callbacks">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="homura.metrics.html">homura.metrics package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="homura.metrics.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="homura.metrics.html#module-homura.metrics.commons">homura.metrics.commons module</a></li>
<li class="toctree-l2"><a class="reference internal" href="homura.metrics.html#module-homura.metrics.segmentation">homura.metrics.segmentation module</a></li>
<li class="toctree-l2"><a class="reference internal" href="homura.metrics.html#module-homura.metrics">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="homura.modules.html">homura.modules package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="homura.modules.html#subpackages">Subpackages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="homura.modules.functional.html">homura.modules.functional package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="homura.modules.functional.html#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="homura.modules.functional.html#module-homura.modules.functional.convert">homura.modules.functional.convert module</a></li>
<li class="toctree-l4"><a class="reference internal" href="homura.modules.functional.html#module-homura.modules.functional.discretization">homura.modules.functional.discretization module</a></li>
<li class="toctree-l4"><a class="reference internal" href="homura.modules.functional.html#module-homura.modules.functional.loss">homura.modules.functional.loss module</a></li>
<li class="toctree-l4"><a class="reference internal" href="homura.modules.functional.html#module-homura.modules.functional">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="homura.modules.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="homura.modules.html#module-homura.modules.attention">homura.modules.attention module</a></li>
<li class="toctree-l2"><a class="reference internal" href="homura.modules.html#module-homura.modules.conditional_batchnorm">homura.modules.conditional_batchnorm module</a></li>
<li class="toctree-l2"><a class="reference internal" href="homura.modules.html#module-homura.modules.discretization">homura.modules.discretization module</a></li>
<li class="toctree-l2"><a class="reference internal" href="homura.modules.html#module-homura.modules.miscs">homura.modules.miscs module</a></li>
<li class="toctree-l2"><a class="reference internal" href="homura.modules.html#module-homura.modules.regularizer">homura.modules.regularizer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="homura.modules.html#module-homura.modules.zca">homura.modules.zca module</a></li>
<li class="toctree-l2"><a class="reference internal" href="homura.modules.html#module-homura.modules">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="homura.utils.html">homura.utils package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="homura.utils.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="homura.utils.html#module-homura.utils.containers">homura.utils.containers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="homura.utils.html#module-homura.utils.environment">homura.utils.environment module</a></li>
<li class="toctree-l2"><a class="reference internal" href="homura.utils.html#module-homura.utils.inferencer">homura.utils.inferencer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="homura.utils.html#module-homura.utils.miscs">homura.utils.miscs module</a></li>
<li class="toctree-l2"><a class="reference internal" href="homura.utils.html#module-homura.utils.reporter_backends">homura.utils.reporter_backends module</a></li>
<li class="toctree-l2"><a class="reference internal" href="homura.utils.html#module-homura.utils.reproducibility">homura.utils.reproducibility module</a></li>
<li class="toctree-l2"><a class="reference internal" href="homura.utils.html#module-homura.utils.runner">homura.utils.runner module</a></li>
<li class="toctree-l2"><a class="reference internal" href="homura.utils.html#module-homura.utils">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="homura.vision.html">homura.vision package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="homura.vision.html#subpackages">Subpackages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="homura.vision.data.html">homura.vision.data package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="homura.vision.data.html#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="homura.vision.data.html#module-homura.vision.data.custom_dataset">homura.vision.data.custom_dataset module</a></li>
<li class="toctree-l4"><a class="reference internal" href="homura.vision.data.html#module-homura.vision.data.folder">homura.vision.data.folder module</a></li>
<li class="toctree-l4"><a class="reference internal" href="homura.vision.data.html#module-homura.vision.data.loaders">homura.vision.data.loaders module</a></li>
<li class="toctree-l4"><a class="reference internal" href="homura.vision.data.html#module-homura.vision.data.prefetcher">homura.vision.data.prefetcher module</a></li>
<li class="toctree-l4"><a class="reference internal" href="homura.vision.data.html#module-homura.vision.data.statistics">homura.vision.data.statistics module</a></li>
<li class="toctree-l4"><a class="reference internal" href="homura.vision.data.html#module-homura.vision.data">Module contents</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="homura.vision.models.html">homura.vision.models package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="homura.vision.models.html#subpackages">Subpackages</a><ul>
<li class="toctree-l5"><a class="reference internal" href="homura.vision.models.classification.html">homura.vision.models.classification package</a><ul>
<li class="toctree-l6"><a class="reference internal" href="homura.vision.models.classification.html#submodules">Submodules</a></li>
<li class="toctree-l6"><a class="reference internal" href="homura.vision.models.classification.html#module-homura.vision.models.classification.densenet">homura.vision.models.classification.densenet module</a></li>
<li class="toctree-l6"><a class="reference internal" href="homura.vision.models.classification.html#module-homura.vision.models.classification.resnet">homura.vision.models.classification.resnet module</a></li>
<li class="toctree-l6"><a class="reference internal" href="homura.vision.models.classification.html#module-homura.vision.models.classification.wideresnet">homura.vision.models.classification.wideresnet module</a></li>
<li class="toctree-l6"><a class="reference internal" href="homura.vision.models.classification.html#module-homura.vision.models.classification">Module contents</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="homura.vision.models.segmentation.html">homura.vision.models.segmentation package</a><ul>
<li class="toctree-l6"><a class="reference internal" href="homura.vision.models.segmentation.html#submodules">Submodules</a></li>
<li class="toctree-l6"><a class="reference internal" href="homura.vision.models.segmentation.html#module-homura.vision.models.segmentation.msdnet">homura.vision.models.segmentation.msdnet module</a></li>
<li class="toctree-l6"><a class="reference internal" href="homura.vision.models.segmentation.html#module-homura.vision.models.segmentation.unet">homura.vision.models.segmentation.unet module</a></li>
<li class="toctree-l6"><a class="reference internal" href="homura.vision.models.segmentation.html#module-homura.vision.models.segmentation">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="homura.vision.models.html#module-homura.vision.models">Module contents</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="homura.vision.transforms.html">homura.vision.transforms package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="homura.vision.transforms.html#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="homura.vision.transforms.html#module-homura.vision.transforms.erase">homura.vision.transforms.erase module</a></li>
<li class="toctree-l4"><a class="reference internal" href="homura.vision.transforms.html#module-homura.vision.transforms.zca">homura.vision.transforms.zca module</a></li>
<li class="toctree-l4"><a class="reference internal" href="homura.vision.transforms.html#module-homura.vision.transforms">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="homura.vision.html#module-homura.vision">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-homura.debug">
<span id="homura-debug-module"></span><h2>homura.debug module<a class="headerlink" href="#module-homura.debug" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="homura.debug.module_debugger">
<code class="sig-prename descclassname">homura.debug.</code><code class="sig-name descname">module_debugger</code><span class="sig-paren">(</span><em class="sig-param">model: torch.nn.modules.module.Module, input: Tuple[torch.Tensor], target: Optional[Tuple[torch.Tensor]] = None, loss: Optional[Callable] = None</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/homura/debug.html#module_debugger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.debug.module_debugger" title="Permalink to this definition">¶</a></dt>
<dd><p>log all modules connected with forward and backward calculation</p>
</dd></dl>

</div>
<div class="section" id="module-homura.liblog">
<span id="homura-liblog-module"></span><h2>homura.liblog module<a class="headerlink" href="#module-homura.liblog" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="homura.liblog.disable_default_handler">
<code class="sig-prename descclassname">homura.liblog.</code><code class="sig-name descname">disable_default_handler</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/homura/liblog.html#disable_default_handler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.liblog.disable_default_handler" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="homura.liblog.enable_default_handler">
<code class="sig-prename descclassname">homura.liblog.</code><code class="sig-name descname">enable_default_handler</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/homura/liblog.html#enable_default_handler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.liblog.enable_default_handler" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="homura.liblog.get_logger">
<code class="sig-prename descclassname">homura.liblog.</code><code class="sig-name descname">get_logger</code><span class="sig-paren">(</span><em class="sig-param">name: str</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/liblog.html#get_logger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.liblog.get_logger" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="homura.liblog.get_verb_level">
<code class="sig-prename descclassname">homura.liblog.</code><code class="sig-name descname">get_verb_level</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="_modules/homura/liblog.html#get_verb_level"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.liblog.get_verb_level" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="homura.liblog.set_file_handler">
<code class="sig-prename descclassname">homura.liblog.</code><code class="sig-name descname">set_file_handler</code><span class="sig-paren">(</span><em class="sig-param">log_file: str</em>, <em class="sig-param">level: str = 10</em>, <em class="sig-param">formatter: Optional[logging.Formatter] = None</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/homura/liblog.html#set_file_handler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.liblog.set_file_handler" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="homura.liblog.set_verb_level">
<code class="sig-prename descclassname">homura.liblog.</code><code class="sig-name descname">set_verb_level</code><span class="sig-paren">(</span><em class="sig-param">level: str</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/homura/liblog.html#set_verb_level"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.liblog.set_verb_level" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-homura.lr_scheduler">
<span id="homura-lr-scheduler-module"></span><h2>homura.lr_scheduler module<a class="headerlink" href="#module-homura.lr_scheduler" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="homura.lr_scheduler.LRScheduler">
<em class="property">class </em><code class="sig-prename descclassname">homura.lr_scheduler.</code><code class="sig-name descname">LRScheduler</code><span class="sig-paren">(</span><em class="sig-param">schdlr_cls</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/lr_scheduler.html#LRScheduler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.lr_scheduler.LRScheduler" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="method">
<dt id="homura.lr_scheduler.LRScheduler.scheduler">
<em class="property">property </em><code class="sig-name descname">scheduler</code><a class="headerlink" href="#homura.lr_scheduler.LRScheduler.scheduler" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.lr_scheduler.LRScheduler.set_optimizer">
<code class="sig-name descname">set_optimizer</code><span class="sig-paren">(</span><em class="sig-param">optimizer: torch.optim.optimizer.Optimizer</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/lr_scheduler.html#LRScheduler.set_optimizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.lr_scheduler.LRScheduler.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="homura.lr_scheduler.StepLR">
<em class="property">class </em><code class="sig-prename descclassname">homura.lr_scheduler.</code><code class="sig-name descname">StepLR</code><span class="sig-paren">(</span><em class="sig-param">step_size</em>, <em class="sig-param">gamma=0.1</em>, <em class="sig-param">last_epoch=-1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/lr_scheduler.html#StepLR"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.lr_scheduler.StepLR" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#homura.lr_scheduler.LRScheduler" title="homura.lr_scheduler.LRScheduler"><code class="xref py py-class docutils literal notranslate"><span class="pre">homura.lr_scheduler.LRScheduler</span></code></a></p>
<p>Decays the learning rate of each parameter group by gamma every
step_size epochs. Notice that such decay can happen simultaneously with
other changes to the learning rate from outside this scheduler. When
last_epoch=-1, sets initial lr as lr.</p>
<dl>
<dt>Args:</dt><dd><p>optimizer (Optimizer): Wrapped optimizer.
step_size (int): Period of learning rate decay.
gamma (float): Multiplicative factor of learning rate decay.</p>
<blockquote>
<div><p>Default: 0.1.</p>
</div></blockquote>
<p>last_epoch (int): The index of last epoch. Default: -1.</p>
</dd>
<dt>Example:</dt><dd><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Assuming optimizer uses lr = 0.05 for all groups</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># lr = 0.05     if epoch &lt; 30</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># lr = 0.005    if 30 &lt;= epoch &lt; 60</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># lr = 0.0005   if 60 &lt;= epoch &lt; 90</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># ...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">train</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">validate</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="homura.lr_scheduler.MultiStepLR">
<em class="property">class </em><code class="sig-prename descclassname">homura.lr_scheduler.</code><code class="sig-name descname">MultiStepLR</code><span class="sig-paren">(</span><em class="sig-param">milestones</em>, <em class="sig-param">gamma=0.1</em>, <em class="sig-param">last_epoch=-1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/lr_scheduler.html#MultiStepLR"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.lr_scheduler.MultiStepLR" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#homura.lr_scheduler.LRScheduler" title="homura.lr_scheduler.LRScheduler"><code class="xref py py-class docutils literal notranslate"><span class="pre">homura.lr_scheduler.LRScheduler</span></code></a></p>
<p>Decays the learning rate of each parameter group by gamma once the
number of epoch reaches one of the milestones. Notice that such decay can
happen simultaneously with other changes to the learning rate from outside
this scheduler. When last_epoch=-1, sets initial lr as lr.</p>
<dl>
<dt>Args:</dt><dd><p>optimizer (Optimizer): Wrapped optimizer.
milestones (list): List of epoch indices. Must be increasing.
gamma (float): Multiplicative factor of learning rate decay.</p>
<blockquote>
<div><p>Default: 0.1.</p>
</div></blockquote>
<p>last_epoch (int): The index of last epoch. Default: -1.</p>
</dd>
<dt>Example:</dt><dd><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Assuming optimizer uses lr = 0.05 for all groups</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># lr = 0.05     if epoch &lt; 30</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># lr = 0.005    if 30 &lt;= epoch &lt; 80</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># lr = 0.0005   if epoch &gt;= 80</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">MultiStepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">milestones</span><span class="o">=</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span><span class="mi">80</span><span class="p">],</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">train</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">validate</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="homura.lr_scheduler.LambdaLR">
<em class="property">class </em><code class="sig-prename descclassname">homura.lr_scheduler.</code><code class="sig-name descname">LambdaLR</code><span class="sig-paren">(</span><em class="sig-param">lr_lambda</em>, <em class="sig-param">last_epoch=-1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/lr_scheduler.html#LambdaLR"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.lr_scheduler.LambdaLR" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#homura.lr_scheduler.LRScheduler" title="homura.lr_scheduler.LRScheduler"><code class="xref py py-class docutils literal notranslate"><span class="pre">homura.lr_scheduler.LRScheduler</span></code></a></p>
<p>Sets the learning rate of each parameter group to the initial lr
times a given function. When last_epoch=-1, sets initial lr as lr.</p>
<dl>
<dt>Args:</dt><dd><p>optimizer (Optimizer): Wrapped optimizer.
lr_lambda (function or list): A function which computes a multiplicative</p>
<blockquote>
<div><p>factor given an integer parameter epoch, or a list of such
functions, one for each group in optimizer.param_groups.</p>
</div></blockquote>
<p>last_epoch (int): The index of last epoch. Default: -1.</p>
</dd>
<dt>Example:</dt><dd><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Assuming optimizer has two groups.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lambda1</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">epoch</span><span class="p">:</span> <span class="n">epoch</span> <span class="o">//</span> <span class="mi">30</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lambda2</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">epoch</span><span class="p">:</span> <span class="mf">0.95</span> <span class="o">**</span> <span class="n">epoch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">LambdaLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_lambda</span><span class="o">=</span><span class="p">[</span><span class="n">lambda1</span><span class="p">,</span> <span class="n">lambda2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">train</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">validate</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="homura.lr_scheduler.ExponentialLR">
<em class="property">class </em><code class="sig-prename descclassname">homura.lr_scheduler.</code><code class="sig-name descname">ExponentialLR</code><span class="sig-paren">(</span><em class="sig-param">gamma</em>, <em class="sig-param">last_epoch=-1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/lr_scheduler.html#ExponentialLR"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.lr_scheduler.ExponentialLR" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#homura.lr_scheduler.LRScheduler" title="homura.lr_scheduler.LRScheduler"><code class="xref py py-class docutils literal notranslate"><span class="pre">homura.lr_scheduler.LRScheduler</span></code></a></p>
<p>Decays the learning rate of each parameter group by gamma every epoch.
When last_epoch=-1, sets initial lr as lr.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>optimizer (Optimizer): Wrapped optimizer.
gamma (float): Multiplicative factor of learning rate decay.
last_epoch (int): The index of last epoch. Default: -1.</p>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="homura.lr_scheduler.CosineAnnealingLR">
<em class="property">class </em><code class="sig-prename descclassname">homura.lr_scheduler.</code><code class="sig-name descname">CosineAnnealingLR</code><span class="sig-paren">(</span><em class="sig-param">T_max</em>, <em class="sig-param">eta_min=0</em>, <em class="sig-param">last_epoch=-1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/lr_scheduler.html#CosineAnnealingLR"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.lr_scheduler.CosineAnnealingLR" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#homura.lr_scheduler.LRScheduler" title="homura.lr_scheduler.LRScheduler"><code class="xref py py-class docutils literal notranslate"><span class="pre">homura.lr_scheduler.LRScheduler</span></code></a></p>
<p>Set the learning rate of each parameter group using a cosine annealing
schedule, where <span class="math notranslate nohighlight">\(\eta_{max}\)</span> is set to the initial lr and
<span class="math notranslate nohighlight">\(T_{cur}\)</span> is the number of epochs since the last restart in SGDR:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\eta_{t+1} = \eta_{min} + (\eta_t - \eta_{min})\frac{1 +
\cos(\frac{T_{cur+1}}{T_{max}}\pi)}{1 + \cos(\frac{T_{cur}}{T_{max}}\pi)},
T_{cur} \neq (2k+1)T_{max};\\
\eta_{t+1} = \eta_{t} + (\eta_{max} - \eta_{min})\frac{1 -
\cos(\frac{1}{T_{max}}\pi)}{2},
T_{cur} = (2k+1)T_{max}.\\\end{split}\]</div>
<p>When last_epoch=-1, sets initial lr as lr. Notice that because the schedule
is defined recursively, the learning rate can be simultaneously modified
outside this scheduler by other operators. If the learning rate is set
solely by this scheduler, the learning rate at each step becomes:</p>
<div class="math notranslate nohighlight">
\[\eta_t = \eta_{min} + \frac{1}{2}(\eta_{max} - \eta_{min})(1 +
\cos(\frac{T_{cur}}{T_{max}}\pi))\]</div>
<p>It has been proposed in
<a class="reference external" href="https://arxiv.org/abs/1608.03983">SGDR: Stochastic Gradient Descent with Warm Restarts</a>. Note that this only
implements the cosine annealing part of SGDR, and not the restarts.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>optimizer (Optimizer): Wrapped optimizer.
T_max (int): Maximum number of iterations.
eta_min (float): Minimum learning rate. Default: 0.
last_epoch (int): The index of last epoch. Default: -1.</p>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="homura.lr_scheduler.ReduceLROnPlateau">
<em class="property">class </em><code class="sig-prename descclassname">homura.lr_scheduler.</code><code class="sig-name descname">ReduceLROnPlateau</code><span class="sig-paren">(</span><em class="sig-param">mode='min'</em>, <em class="sig-param">factor=0.1</em>, <em class="sig-param">patience=10</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">threshold=0.0001</em>, <em class="sig-param">threshold_mode='rel'</em>, <em class="sig-param">cooldown=0</em>, <em class="sig-param">min_lr=0</em>, <em class="sig-param">eps=1e-08</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/lr_scheduler.html#ReduceLROnPlateau"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.lr_scheduler.ReduceLROnPlateau" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#homura.lr_scheduler.LRScheduler" title="homura.lr_scheduler.LRScheduler"><code class="xref py py-class docutils literal notranslate"><span class="pre">homura.lr_scheduler.LRScheduler</span></code></a></p>
<p>Reduce learning rate when a metric has stopped improving.
Models often benefit from reducing the learning rate by a factor
of 2-10 once learning stagnates. This scheduler reads a metrics
quantity and if no improvement is seen for a ‘patience’ number
of epochs, the learning rate is reduced.</p>
<dl>
<dt>Args:</dt><dd><p>optimizer (Optimizer): Wrapped optimizer.
mode (str): One of <cite>min</cite>, <cite>max</cite>. In <cite>min</cite> mode, lr will</p>
<blockquote>
<div><p>be reduced when the quantity monitored has stopped
decreasing; in <cite>max</cite> mode it will be reduced when the
quantity monitored has stopped increasing. Default: ‘min’.</p>
</div></blockquote>
<dl class="simple">
<dt>factor (float): Factor by which the learning rate will be</dt><dd><p>reduced. new_lr = lr * factor. Default: 0.1.</p>
</dd>
<dt>patience (int): Number of epochs with no improvement after</dt><dd><p>which learning rate will be reduced. For example, if
<cite>patience = 2</cite>, then we will ignore the first 2 epochs
with no improvement, and will only decrease the LR after the
3rd epoch if the loss still hasn’t improved then.
Default: 10.</p>
</dd>
<dt>verbose (bool): If <code class="docutils literal notranslate"><span class="pre">True</span></code>, prints a message to stdout for</dt><dd><p>each update. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd>
<dt>threshold (float): Threshold for measuring the new optimum,</dt><dd><p>to only focus on significant changes. Default: 1e-4.</p>
</dd>
<dt>threshold_mode (str): One of <cite>rel</cite>, <cite>abs</cite>. In <cite>rel</cite> mode,</dt><dd><p>dynamic_threshold = best * ( 1 + threshold ) in ‘max’
mode or best * ( 1 - threshold ) in <cite>min</cite> mode.
In <cite>abs</cite> mode, dynamic_threshold = best + threshold in
<cite>max</cite> mode or best - threshold in <cite>min</cite> mode. Default: ‘rel’.</p>
</dd>
<dt>cooldown (int): Number of epochs to wait before resuming</dt><dd><p>normal operation after lr has been reduced. Default: 0.</p>
</dd>
<dt>min_lr (float or list): A scalar or a list of scalars. A</dt><dd><p>lower bound on the learning rate of all param groups
or each group respectively. Default: 0.</p>
</dd>
<dt>eps (float): Minimal decay applied to lr. If the difference</dt><dd><p>between new and old lr is smaller than eps, the update is
ignored. Default: 1e-8.</p>
</dd>
</dl>
</dd>
<dt>Example:</dt><dd><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">train</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">val_loss</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="c1"># Note that step should be called after validate()</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-homura.optim">
<span id="homura-optim-module"></span><h2>homura.optim module<a class="headerlink" href="#module-homura.optim" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="homura.optim.Optimizer">
<em class="property">class </em><code class="sig-prename descclassname">homura.optim.</code><code class="sig-name descname">Optimizer</code><span class="sig-paren">(</span><em class="sig-param">optim_cls</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/optim.html#Optimizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.optim.Optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="method">
<dt id="homura.optim.Optimizer.optim">
<em class="property">property </em><code class="sig-name descname">optim</code><a class="headerlink" href="#homura.optim.Optimizer.optim" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.optim.Optimizer.set_model">
<code class="sig-name descname">set_model</code><span class="sig-paren">(</span><em class="sig-param">params: Iterable[torch.Tensor]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/optim.html#Optimizer.set_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.optim.Optimizer.set_model" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="homura.optim.Adam">
<em class="property">class </em><code class="sig-prename descclassname">homura.optim.</code><code class="sig-name descname">Adam</code><span class="sig-paren">(</span><em class="sig-param">lr=0.001</em>, <em class="sig-param">betas=(0.9</em>, <em class="sig-param">0.999)</em>, <em class="sig-param">eps=1e-08</em>, <em class="sig-param">weight_decay=0</em>, <em class="sig-param">amsgrad=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/optim.html#Adam"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.optim.Adam" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#homura.optim.Optimizer" title="homura.optim.Optimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">homura.optim.Optimizer</span></code></a></p>
<p>Implements Adam algorithm.</p>
<p>It has been proposed in <a class="reference external" href="https://arxiv.org/abs/1412.6980">Adam: A Method for Stochastic Optimization</a>.</p>
<dl>
<dt>Arguments:</dt><dd><dl class="simple">
<dt>params (iterable): iterable of parameters to optimize or dicts defining</dt><dd><p>parameter groups</p>
</dd>
</dl>
<p>lr (float, optional): learning rate (default: 1e-3)
betas (Tuple[float, float], optional): coefficients used for computing</p>
<blockquote>
<div><p>running averages of gradient and its square (default: (0.9, 0.999))</p>
</div></blockquote>
<dl class="simple">
<dt>eps (float, optional): term added to the denominator to improve</dt><dd><p>numerical stability (default: 1e-8)</p>
</dd>
</dl>
<p>weight_decay (float, optional): weight decay (L2 penalty) (default: 0)
amsgrad (boolean, optional): whether to use the AMSGrad variant of this</p>
<blockquote>
<div><p>algorithm from the paper <a class="reference external" href="https://openreview.net/forum?id=ryQu7f-RZ">On the Convergence of Adam and Beyond</a>
(default: False)</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="homura.optim.SGD">
<em class="property">class </em><code class="sig-prename descclassname">homura.optim.</code><code class="sig-name descname">SGD</code><span class="sig-paren">(</span><em class="sig-param">lr</em>, <em class="sig-param">momentum=0</em>, <em class="sig-param">dampening=0</em>, <em class="sig-param">weight_decay=0</em>, <em class="sig-param">nesterov=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/optim.html#SGD"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.optim.SGD" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#homura.optim.Optimizer" title="homura.optim.Optimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">homura.optim.Optimizer</span></code></a></p>
<p>Implements stochastic gradient descent (optionally with momentum).</p>
<p>Nesterov momentum is based on the formula from
<a class="reference external" href="http://www.cs.toronto.edu/%7Ehinton/absps/momentum.pdf">On the importance of initialization and momentum in deep learning</a>.</p>
<dl>
<dt>Args:</dt><dd><dl class="simple">
<dt>params (iterable): iterable of parameters to optimize or dicts defining</dt><dd><p>parameter groups</p>
</dd>
</dl>
<p>lr (float): learning rate
momentum (float, optional): momentum factor (default: 0)
weight_decay (float, optional): weight decay (L2 penalty) (default: 0)
dampening (float, optional): dampening for momentum (default: 0)
nesterov (bool, optional): enables Nesterov momentum (default: False)</p>
</dd>
<dt>Example:</dt><dd><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss_fn</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The implementation of SGD with Momentum/Nesterov subtly differs from
Sutskever et. al. and implementations in some other frameworks.</p>
<p>Considering the specific case of Momentum, the update can be written as</p>
<div class="math notranslate nohighlight">
\[\begin{split}v = \rho * v + g \\
p = p - lr * v\end{split}\]</div>
<p>where p, g, v and <span class="math notranslate nohighlight">\(\rho\)</span> denote the parameters, gradient,
velocity, and momentum respectively.</p>
<p>This is in contrast to Sutskever et. al. and
other frameworks which employ an update of the form</p>
<div class="math notranslate nohighlight">
\[\begin{split}v = \rho * v + lr * g \\
p = p - v\end{split}\]</div>
<p>The Nesterov version is analogously modified.</p>
</div>
</dd></dl>

<dl class="class">
<dt id="homura.optim.ASGD">
<em class="property">class </em><code class="sig-prename descclassname">homura.optim.</code><code class="sig-name descname">ASGD</code><span class="sig-paren">(</span><em class="sig-param">lr=0.01</em>, <em class="sig-param">lambd=0.0001</em>, <em class="sig-param">alpha=0.75</em>, <em class="sig-param">t0=1000000.0</em>, <em class="sig-param">weight_decay=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/optim.html#ASGD"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.optim.ASGD" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#homura.optim.Optimizer" title="homura.optim.Optimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">homura.optim.Optimizer</span></code></a></p>
<p>Implements Averaged Stochastic Gradient Descent.</p>
<p>It has been proposed in <a class="reference external" href="http://dl.acm.org/citation.cfm?id=131098">Acceleration of stochastic approximation by
averaging</a>.</p>
<dl>
<dt>Arguments:</dt><dd><dl class="simple">
<dt>params (iterable): iterable of parameters to optimize or dicts defining</dt><dd><p>parameter groups</p>
</dd>
</dl>
<p>lr (float, optional): learning rate (default: 1e-2)
lambd (float, optional): decay term (default: 1e-4)
alpha (float, optional): power for eta update (default: 0.75)
t0 (float, optional): point at which to start averaging (default: 1e6)
weight_decay (float, optional): weight decay (L2 penalty) (default: 0)</p>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="homura.optim.RMSProp">
<em class="property">class </em><code class="sig-prename descclassname">homura.optim.</code><code class="sig-name descname">RMSProp</code><span class="sig-paren">(</span><em class="sig-param">lr=0.01</em>, <em class="sig-param">alpha=0.99</em>, <em class="sig-param">eps=1e-08</em>, <em class="sig-param">weight_decay=0</em>, <em class="sig-param">momentum=0</em>, <em class="sig-param">centered=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/optim.html#RMSProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.optim.RMSProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#homura.optim.Optimizer" title="homura.optim.Optimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">homura.optim.Optimizer</span></code></a></p>
<p>Implements RMSprop algorithm.</p>
<p>Proposed by G. Hinton in his
<a class="reference external" href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf">course</a>.</p>
<p>The centered version first appears in <a class="reference external" href="https://arxiv.org/pdf/1308.0850v5.pdf">Generating Sequences
With Recurrent Neural Networks</a>.</p>
<dl>
<dt>Arguments:</dt><dd><dl class="simple">
<dt>params (iterable): iterable of parameters to optimize or dicts defining</dt><dd><p>parameter groups</p>
</dd>
</dl>
<p>lr (float, optional): learning rate (default: 1e-2)
momentum (float, optional): momentum factor (default: 0)
alpha (float, optional): smoothing constant (default: 0.99)
eps (float, optional): term added to the denominator to improve</p>
<blockquote>
<div><p>numerical stability (default: 1e-8)</p>
</div></blockquote>
<dl>
<dt>centered (bool, optional)<span class="classifier">if <code class="docutils literal notranslate"><span class="pre">True</span></code>, compute the centered RMSProp,</span></dt><dd><p>the gradient is normalized by an estimation of its variance</p>
</dd>
</dl>
<p>weight_decay (float, optional): weight decay (L2 penalty) (default: 0)</p>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="homura.optim.AdaBound">
<em class="property">class </em><code class="sig-prename descclassname">homura.optim.</code><code class="sig-name descname">AdaBound</code><span class="sig-paren">(</span><em class="sig-param">lr=0.001</em>, <em class="sig-param">betas=(0.9</em>, <em class="sig-param">0.999)</em>, <em class="sig-param">final_lr=0.1</em>, <em class="sig-param">gamma=0.001</em>, <em class="sig-param">eps=1e-08</em>, <em class="sig-param">weight_decay=0</em>, <em class="sig-param">amsbound=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/optim.html#AdaBound"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.optim.AdaBound" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#homura.optim.Optimizer" title="homura.optim.Optimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">homura.optim.Optimizer</span></code></a></p>
<p>Implements AdaBound algorithm.
It has been proposed in <a href="#id2"><span class="problematic" id="id3">`Adaptive Gradient Methods with Dynamic Bound of Learning Rate`_</span></a>.
Arguments:</p>
<blockquote>
<div><dl class="simple">
<dt>params (iterable): iterable of parameters to optimize or dicts defining</dt><dd><p>parameter groups</p>
</dd>
</dl>
<p>lr (float, optional): Adam learning rate (default: 1e-3)
betas (Tuple[float, float], optional): coefficients used for computing</p>
<blockquote>
<div><p>running averages of gradient and its square (default: (0.9, 0.999))</p>
</div></blockquote>
<p>final_lr (float, optional): final (SGD) learning rate (default: 0.1)
gamma (float, optional): convergence speed of the bound functions (default: 1e-3)
eps (float, optional): term added to the denominator to improve</p>
<blockquote>
<div><p>numerical stability (default: 1e-8)</p>
</div></blockquote>
<p>weight_decay (float, optional): weight decay (L2 penalty) (default: 0)
amsbound (boolean, optional): whether to use the AMSBound variant of this algorithm</p>
</div></blockquote>
</dd></dl>

</div>
<div class="section" id="module-homura.reporters">
<span id="homura-reporters-module"></span><h2>homura.reporters module<a class="headerlink" href="#module-homura.reporters" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="homura.reporters.LoggerReporter">
<em class="property">class </em><code class="sig-prename descclassname">homura.reporters.</code><code class="sig-name descname">LoggerReporter</code><span class="sig-paren">(</span><em class="sig-param">callbacks: Union[Iterable[homura.callbacks.base.Callback], homura.callbacks.base.Callback], save_dir: Optional[str] = None, logger: Optional[logging.Logger] = None, report_freq: int = -1, save_image_freq: int = 0, image_keys: Optional[Iterable[str]] = None, save_log: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/reporters.html#LoggerReporter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.reporters.LoggerReporter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#homura.reporters.Reporter" title="homura.reporters.Reporter"><code class="xref py py-class docutils literal notranslate"><span class="pre">homura.reporters.Reporter</span></code></a></p>
<p>Something like this</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">LoggerReporter</span><span class="p">(</span><span class="o">...</span><span class="p">)</span> <span class="k">as</span> <span class="n">lr</span><span class="p">:</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="o">...</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="o">...</span>
</pre></div>
</div>
<p>Reports like this</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">homura</span><span class="o">.</span><span class="n">reporter</span><span class="o">|</span><span class="mi">2019</span><span class="o">-</span><span class="mi">02</span><span class="o">-</span><span class="mi">30</span> <span class="mi">27</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mi">20</span><span class="o">|</span><span class="n">INFO</span><span class="p">]</span> <span class="p">[</span>      <span class="mi">1</span><span class="p">]</span>                      <span class="n">loss_test</span> <span class="mf">0.4413</span>
<span class="p">[</span><span class="n">homura</span><span class="o">.</span><span class="n">reporter</span><span class="o">|</span><span class="mi">2019</span><span class="o">-</span><span class="mi">02</span><span class="o">-</span><span class="mi">30</span> <span class="mi">27</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mi">20</span><span class="o">|</span><span class="n">INFO</span><span class="p">]</span> <span class="p">[</span>      <span class="mi">1</span><span class="p">]</span>                  <span class="n">accuracy_test</span> <span class="mf">0.8631</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>callbacks</strong> – </p></li>
<li><p><strong>save_dir</strong> – </p></li>
<li><p><strong>report_freq</strong> – </p></li>
<li><p><strong>save_image_freq</strong> – If n&gt;0, saves images every n iteration. if n==-1, every epoch.
This may need large storage space.</p></li>
<li><p><strong>image_keys</strong> – keys for images.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="homura.reporters.Reporter">
<em class="property">class </em><code class="sig-prename descclassname">homura.reporters.</code><code class="sig-name descname">Reporter</code><span class="sig-paren">(</span><em class="sig-param">base_wrapper: homura.utils.reporter_backends._WrapperBase, callbacks: Union[Iterable[homura.callbacks.base.Callback], homura.callbacks.base.Callback], report_freq: int = -1, report_param_freq: int = 0, report_image_freq: int = 0, image_keys: Optional[Iterable[str]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/reporters.html#Reporter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.reporters.Reporter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="homura.callbacks.html#homura.callbacks.base.Callback" title="homura.callbacks.base.Callback"><code class="xref py py-class docutils literal notranslate"><span class="pre">homura.callbacks.base.Callback</span></code></a></p>
<dl class="method">
<dt id="homura.reporters.Reporter.add_memo">
<code class="sig-name descname">add_memo</code><span class="sig-paren">(</span><em class="sig-param">text: str</em>, <em class="sig-param">*</em>, <em class="sig-param">name='memo'</em>, <em class="sig-param">index=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/reporters.html#Reporter.add_memo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.reporters.Reporter.add_memo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.reporters.Reporter.after_all">
<code class="sig-name descname">after_all</code><span class="sig-paren">(</span><em class="sig-param">data: Mapping</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/reporters.html#Reporter.after_all"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.reporters.Reporter.after_all" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.reporters.Reporter.after_epoch">
<code class="sig-name descname">after_epoch</code><span class="sig-paren">(</span><em class="sig-param">data: Mapping</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/reporters.html#Reporter.after_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.reporters.Reporter.after_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.reporters.Reporter.after_iteration">
<code class="sig-name descname">after_iteration</code><span class="sig-paren">(</span><em class="sig-param">data: Mapping</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/reporters.html#Reporter.after_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.reporters.Reporter.after_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.reporters.Reporter.before_all">
<code class="sig-name descname">before_all</code><span class="sig-paren">(</span><em class="sig-param">data: Mapping</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/reporters.html#Reporter.before_all"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.reporters.Reporter.before_all" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.reporters.Reporter.before_epoch">
<code class="sig-name descname">before_epoch</code><span class="sig-paren">(</span><em class="sig-param">data: Mapping</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/reporters.html#Reporter.before_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.reporters.Reporter.before_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.reporters.Reporter.before_iteration">
<code class="sig-name descname">before_iteration</code><span class="sig-paren">(</span><em class="sig-param">data: Mapping</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/reporters.html#Reporter.before_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.reporters.Reporter.before_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.reporters.Reporter.close">
<code class="sig-name descname">close</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/reporters.html#Reporter.close"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.reporters.Reporter.close" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.reporters.Reporter.disable_report_images">
<code class="sig-name descname">disable_report_images</code><span class="sig-paren">(</span><em class="sig-param">image_keys: Union[str</em>, <em class="sig-param">list</em>, <em class="sig-param">None] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/reporters.html#Reporter.disable_report_images"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.reporters.Reporter.disable_report_images" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.reporters.Reporter.disable_report_params">
<code class="sig-name descname">disable_report_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/reporters.html#Reporter.disable_report_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.reporters.Reporter.disable_report_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.reporters.Reporter.enable_report_images">
<code class="sig-name descname">enable_report_images</code><span class="sig-paren">(</span><em class="sig-param">report_freq: int = -1</em>, <em class="sig-param">image_keys: Union[str</em>, <em class="sig-param">list] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/reporters.html#Reporter.enable_report_images"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.reporters.Reporter.enable_report_images" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.reporters.Reporter.enable_report_params">
<code class="sig-name descname">enable_report_params</code><span class="sig-paren">(</span><em class="sig-param">report_freq: int = -1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/reporters.html#Reporter.enable_report_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.reporters.Reporter.enable_report_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="homura.reporters.TQDMReporter">
<em class="property">class </em><code class="sig-prename descclassname">homura.reporters.</code><code class="sig-name descname">TQDMReporter</code><span class="sig-paren">(</span><em class="sig-param">iterator: Iterable, callbacks: Union[Iterable[homura.callbacks.base.Callback], homura.callbacks.base.Callback], save_dir: Optional[str] = None, report_freq: int = -1, save_image_freq: int = 0, image_keys: Optional[Iterable[str]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/reporters.html#TQDMReporter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.reporters.TQDMReporter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#homura.reporters.Reporter" title="homura.reporters.Reporter"><code class="xref py py-class docutils literal notranslate"><span class="pre">homura.reporters.Reporter</span></code></a></p>
<p>Reporter using tqdm. Use like</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">TQDMReporter</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">),</span> <span class="n">callbacks</span><span class="p">)</span> <span class="k">as</span> <span class="n">tq</span><span class="p">:</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="o">...</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">tq</span><span class="p">:</span>
        <span class="o">...</span>
</pre></div>
</div>
<p>The output is like</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>100%|█| 200/200 [1:01:10&lt;00:00, 18.44s/it, loss_test=0.358, accuracy_test=0.919]
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>iterator</strong> – </p></li>
<li><p><strong>callbacks</strong> – </p></li>
<li><p><strong>save_dir</strong> – </p></li>
<li><p><strong>report_freq</strong> – </p></li>
<li><p><strong>save_image_freq</strong> – If n&gt;0, saves images every n iteration. if n==-1, every epoch.
This may need large storage space.</p></li>
<li><p><strong>image_keys</strong> – keys for images.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="homura.reporters.TensorboardReporter">
<em class="property">class </em><code class="sig-prename descclassname">homura.reporters.</code><code class="sig-name descname">TensorboardReporter</code><span class="sig-paren">(</span><em class="sig-param">callbacks: Union[Iterable[homura.callbacks.base.Callback], homura.callbacks.base.Callback], save_dir=None, report_freq: int = -1, report_params_freq: int = 0, report_images_freq: int = 0, image_keys: Optional[Iterable[str]] = None, save_images: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/reporters.html#TensorboardReporter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.reporters.TensorboardReporter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#homura.reporters.Reporter" title="homura.reporters.Reporter"><code class="xref py py-class docutils literal notranslate"><span class="pre">homura.reporters.Reporter</span></code></a></p>
<p>Reporter using Tensorboard.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">TensorboardReporter</span><span class="p">(</span><span class="o">...</span><span class="p">)</span> <span class="k">as</span> <span class="n">tb</span><span class="p">:</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="o">...</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="o">...</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>callbacks</strong> – </p></li>
<li><p><strong>save_dir</strong> – </p></li>
<li><p><strong>report_freq</strong> – </p></li>
<li><p><strong>report_params_freq</strong> – If n&gt;0, reports parameter histograms every n iteration. if n==-1, every epoch.</p></li>
<li><p><strong>report_images_freq</strong> – If n&gt;0, reports images every n iteration. if n==-1, every epoch.</p></li>
<li><p><strong>image_keys</strong> – keys for images.</p></li>
<li><p><strong>save_images</strong> – If True, saving images in addition to reporting</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="homura.reporters.VisdomReporter">
<em class="property">class </em><code class="sig-prename descclassname">homura.reporters.</code><code class="sig-name descname">VisdomReporter</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/reporters.html#VisdomReporter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.reporters.VisdomReporter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Deprecated. Use TensorboardReporter instead.</p>
</dd></dl>

</div>
<div class="section" id="module-homura.trainers">
<span id="homura-trainers-module"></span><h2>homura.trainers module<a class="headerlink" href="#module-homura.trainers" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="homura.trainers.TrainerBase">
<em class="property">class </em><code class="sig-prename descclassname">homura.trainers.</code><code class="sig-name descname">TrainerBase</code><span class="sig-paren">(</span><em class="sig-param">model: torch.nn.modules.module.Module, optimizer: Optional[homura.optim.Optimizer], loss_f: Optional[Callable], *, callbacks: Optional[homura.callbacks.base.Callback] = None, scheduler: Optional[homura.lr_scheduler.LRScheduler] = None, update_scheduler_by_epoch: bool = True, device: Optional[torch.device] = None, verb=True, use_cudnn_benchmark=True, use_cuda_nonblocking=False, logger=None, **kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/trainers.html#TrainerBase"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.trainers.TrainerBase" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="homura.utils.html#homura.utils.runner.Runner" title="homura.utils.runner.Runner"><code class="xref py py-class docutils literal notranslate"><span class="pre">homura.utils.runner.Runner</span></code></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – nn.Module or dict like {“generator”: gen, “discriminator”: dis}</p></li>
<li><p><strong>optimizer</strong> – homura.optimizer.Optimizer or dict like {“generator”: Adam(lr=3e-4)}</p></li>
<li><p><strong>loss_f</strong> – loss function or dict of loss functions</p></li>
<li><p><strong>callbacks</strong> – callbacks or list of callbacks</p></li>
<li><p><strong>scheduler</strong> – homura.scheduler.LRScheduler or dict like {“generator”: StepLR(10)}</p></li>
<li><p><strong>update_scheduler_by_epoch</strong> – If True, update scheduler every epoch. If False and scheduler is given, scheduler
is need to be update by user.</p></li>
<li><p><strong>device</strong> – </p></li>
<li><p><strong>verb</strong> – </p></li>
<li><p><strong>use_cudnn_benchmark</strong> – </p></li>
<li><p><strong>use_cuda_nonblocking</strong> – </p></li>
<li><p><strong>logger</strong> – </p></li>
<li><p><strong>kwargs</strong> – </p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="homura.trainers.TrainerBase.epoch">
<em class="property">property </em><code class="sig-name descname">epoch</code><a class="headerlink" href="#homura.trainers.TrainerBase.epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.trainers.TrainerBase.exit">
<code class="sig-name descname">exit</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/trainers.html#TrainerBase.exit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.trainers.TrainerBase.exit" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.trainers.TrainerBase.is_train">
<em class="property">property </em><code class="sig-name descname">is_train</code><a class="headerlink" href="#homura.trainers.TrainerBase.is_train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.trainers.TrainerBase.iteration">
<em class="property">abstract </em><code class="sig-name descname">iteration</code><span class="sig-paren">(</span><em class="sig-param">data: Iterable[torch.Tensor]</em><span class="sig-paren">)</span> &#x2192; Mapping[str, torch.Tensor]<a class="reference internal" href="_modules/homura/trainers.html#TrainerBase.iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.trainers.TrainerBase.iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Iteration part, user can override via duck typing or override_iteration</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">iteration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
    <span class="nb">input</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_f</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_train</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">Map</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> – data used during a iteration</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>loss, output</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="homura.trainers.TrainerBase.override_iteration">
<code class="sig-name descname">override_iteration</code><span class="sig-paren">(</span><em class="sig-param">new_iteration: Callable</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/trainers.html#TrainerBase.override_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.trainers.TrainerBase.override_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Override iteration method</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">new_iteration</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="nb">input</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span>
    <span class="o">...</span>
    <span class="n">results</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span>
    <span class="k">return</span> <span class="n">results</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">update_iteration</span><span class="p">(</span><span class="n">new_iteration</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>new_iteration</strong> – </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="homura.trainers.TrainerBase.register_after_all">
<code class="sig-name descname">register_after_all</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">data</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/trainers.html#TrainerBase.register_after_all"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.trainers.TrainerBase.register_after_all" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.trainers.TrainerBase.register_after_epoch">
<code class="sig-name descname">register_after_epoch</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">data</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/trainers.html#TrainerBase.register_after_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.trainers.TrainerBase.register_after_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.trainers.TrainerBase.register_after_iteration">
<code class="sig-name descname">register_after_iteration</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">data</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/trainers.html#TrainerBase.register_after_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.trainers.TrainerBase.register_after_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.trainers.TrainerBase.register_before_all">
<code class="sig-name descname">register_before_all</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">data</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/trainers.html#TrainerBase.register_before_all"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.trainers.TrainerBase.register_before_all" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.trainers.TrainerBase.register_before_epoch">
<code class="sig-name descname">register_before_epoch</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">data</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/trainers.html#TrainerBase.register_before_epoch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.trainers.TrainerBase.register_before_epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.trainers.TrainerBase.register_before_iteration">
<code class="sig-name descname">register_before_iteration</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">data</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/trainers.html#TrainerBase.register_before_iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.trainers.TrainerBase.register_before_iteration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.trainers.TrainerBase.resume">
<code class="sig-name descname">resume</code><span class="sig-paren">(</span><em class="sig-param">path: str</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/trainers.html#TrainerBase.resume"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.trainers.TrainerBase.resume" title="Permalink to this definition">¶</a></dt>
<dd><p>Resume training from saved states by <cite>homura.callbacks.WeightSave</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>path</strong> – </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="homura.trainers.TrainerBase.run">
<code class="sig-name descname">run</code><span class="sig-paren">(</span><em class="sig-param">epochs: int</em>, <em class="sig-param">train_data: torch.utils.data.dataloader.DataLoader</em>, <em class="sig-param">test_data: torch.utils.data.dataloader.DataLoader</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/trainers.html#TrainerBase.run"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.trainers.TrainerBase.run" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.trainers.TrainerBase.step">
<em class="property">property </em><code class="sig-name descname">step</code><a class="headerlink" href="#homura.trainers.TrainerBase.step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.trainers.TrainerBase.test">
<code class="sig-name descname">test</code><span class="sig-paren">(</span><em class="sig-param">data_loader: torch.utils.data.dataloader.DataLoader</em>, <em class="sig-param">mode: str = 'test'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/trainers.html#TrainerBase.test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.trainers.TrainerBase.test" title="Permalink to this definition">¶</a></dt>
<dd><p>Non-training loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_loader</strong> – </p></li>
<li><p><strong>mode</strong> – Name of this loop. Default is <cite>test</cite>. Passed to callbacks.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="homura.trainers.TrainerBase.train">
<code class="sig-name descname">train</code><span class="sig-paren">(</span><em class="sig-param">data_loader: torch.utils.data.dataloader.DataLoader</em>, <em class="sig-param">mode: str = 'train'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/trainers.html#TrainerBase.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.trainers.TrainerBase.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Training loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_loader</strong> – </p></li>
<li><p><strong>mode</strong> – Name of this loop. Default is <cite>train</cite>. Passed to callbacks.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="homura.trainers.TrainerBase.update_scheduler">
<code class="sig-name descname">update_scheduler</code><span class="sig-paren">(</span><em class="sig-param">scheduler: homura.lr_scheduler.LRScheduler</em>, <em class="sig-param">update_scheduler_by_epoch: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/trainers.html#TrainerBase.update_scheduler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.trainers.TrainerBase.update_scheduler" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="attribute">
<dt id="homura.trainers.Trainer">
<code class="sig-prename descclassname">homura.trainers.</code><code class="sig-name descname">Trainer</code><a class="headerlink" href="#homura.trainers.Trainer" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#homura.trainers.SupervisedTrainer" title="homura.trainers.SupervisedTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">homura.trainers.SupervisedTrainer</span></code></a></p>
</dd></dl>

<dl class="class">
<dt id="homura.trainers.SupervisedTrainer">
<em class="property">class </em><code class="sig-prename descclassname">homura.trainers.</code><code class="sig-name descname">SupervisedTrainer</code><span class="sig-paren">(</span><em class="sig-param">model: torch.nn.modules.module.Module</em>, <em class="sig-param">optimizer: homura.optim.Optimizer</em>, <em class="sig-param">loss_f: Callable</em>, <em class="sig-param">*</em>, <em class="sig-param">callbacks: Optional[homura.callbacks.base.Callback] = None</em>, <em class="sig-param">scheduler: Optional[homura.lr_scheduler.LRScheduler] = None</em>, <em class="sig-param">verb=True</em>, <em class="sig-param">use_cudnn_benchmark=True</em>, <em class="sig-param">data_parallel=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/trainers.html#SupervisedTrainer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.trainers.SupervisedTrainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#homura.trainers.TrainerBase" title="homura.trainers.TrainerBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">homura.trainers.TrainerBase</span></code></a></p>
<dl class="method">
<dt id="homura.trainers.SupervisedTrainer.iteration">
<code class="sig-name descname">iteration</code><span class="sig-paren">(</span><em class="sig-param">data: Tuple[torch.Tensor]</em><span class="sig-paren">)</span> &#x2192; Mapping[str, torch.Tensor]<a class="reference internal" href="_modules/homura/trainers.html#SupervisedTrainer.iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.trainers.SupervisedTrainer.iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Iteration part, user can override via duck typing or override_iteration</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">iteration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
    <span class="nb">input</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_f</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_train</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">Map</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> – data used during a iteration</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>loss, output</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="homura.trainers.DistributedSupervisedTrainer">
<em class="property">class </em><code class="sig-prename descclassname">homura.trainers.</code><code class="sig-name descname">DistributedSupervisedTrainer</code><span class="sig-paren">(</span><em class="sig-param">model: torch.nn.modules.module.Module</em>, <em class="sig-param">optimizer: homura.optim.Optimizer</em>, <em class="sig-param">loss_f: Callable</em>, <em class="sig-param">*</em>, <em class="sig-param">callbacks: homura.callbacks.base.Callback = None</em>, <em class="sig-param">scheduler: homura.lr_scheduler.LRScheduler = None</em>, <em class="sig-param">verb=True</em>, <em class="sig-param">use_cudnn_benchmark=True</em>, <em class="sig-param">backend='nccl'</em>, <em class="sig-param">init_method='env://'</em>, <em class="sig-param">use_sync_bn: bool = False</em>, <em class="sig-param">enable_amp=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/trainers.html#DistributedSupervisedTrainer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.trainers.DistributedSupervisedTrainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#homura.trainers.SupervisedTrainer" title="homura.trainers.SupervisedTrainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">homura.trainers.SupervisedTrainer</span></code></a></p>
<p>Trainer with distributed functions</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – </p></li>
<li><p><strong>optimizer</strong> – </p></li>
<li><p><strong>loss_f</strong> – </p></li>
<li><p><strong>callbacks</strong> – </p></li>
<li><p><strong>scheduler</strong> – </p></li>
<li><p><strong>verb</strong> – </p></li>
<li><p><strong>use_cudnn_benchmark</strong> – </p></li>
<li><p><strong>backend</strong> – “nccl” or “gloo”</p></li>
<li><p><strong>init_method</strong> – </p></li>
<li><p><strong>use_sync_bn</strong> – </p></li>
<li><p><strong>kwargs</strong> – </p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="homura.trainers.DistributedSupervisedTrainer.iteration">
<code class="sig-name descname">iteration</code><span class="sig-paren">(</span><em class="sig-param">data: Tuple[torch.Tensor]</em><span class="sig-paren">)</span> &#x2192; Mapping[str, torch.Tensor]<a class="reference internal" href="_modules/homura/trainers.html#DistributedSupervisedTrainer.iteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.trainers.DistributedSupervisedTrainer.iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Iteration part, user can override via duck typing or override_iteration</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">iteration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
    <span class="nb">input</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_f</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_train</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">Map</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> – data used during a iteration</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>loss, output</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-homura">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-homura" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="homura.Map">
<em class="property">class </em><code class="sig-prename descclassname">homura.</code><code class="sig-name descname">Map</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/utils/containers.html#Map"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.Map" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">collections.abc.MutableMapping</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></p>
<p>dict like object but: stored values can be subscribed and attributed.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Map</span><span class="p">(</span><span class="n">test</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">test</span> <span class="ow">is</span> <span class="n">m</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span>
</pre></div>
</div>
<dl class="method">
<dt id="homura.Map.copy">
<code class="sig-name descname">copy</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; a shallow copy of D<a class="reference internal" href="_modules/homura/utils/containers.html#Map.copy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.Map.copy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.Map.deepcopy">
<code class="sig-name descname">deepcopy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/utils/containers.html#Map.deepcopy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.Map.deepcopy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.Map.keys">
<code class="sig-name descname">keys</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; a set-like object providing a view on D's keys<a class="reference internal" href="_modules/homura/utils/containers.html#Map.keys"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.Map.keys" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="homura.Map.to">
<code class="sig-name descname">to</code><span class="sig-paren">(</span><em class="sig-param">device: str</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/utils/containers.html#Map.to"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.Map.to" title="Permalink to this definition">¶</a></dt>
<dd><p>Move stored tensors to a given device</p>
</dd></dl>

<dl class="method">
<dt id="homura.Map.values">
<code class="sig-name descname">values</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; an object providing a view on D's values<a class="reference internal" href="_modules/homura/utils/containers.html#Map.values"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.Map.values" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="homura.TensorTuple">
<em class="property">class </em><code class="sig-prename descclassname">homura.</code><code class="sig-name descname">TensorTuple</code><a class="reference internal" href="_modules/homura/utils/containers.html#TensorTuple"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.TensorTuple" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></p>
<p>Tuple for tensors.</p>
<dl class="method">
<dt id="homura.TensorTuple.to">
<code class="sig-name descname">to</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/homura/utils/containers.html#TensorTuple.to"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.TensorTuple.to" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="homura.enable_accimage">
<code class="sig-prename descclassname">homura.</code><code class="sig-name descname">enable_accimage</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/homura/utils/environment.html#enable_accimage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.enable_accimage" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="homura.get_global_rank">
<code class="sig-prename descclassname">homura.</code><code class="sig-name descname">get_global_rank</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="_modules/homura/utils/environment.html#get_global_rank"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.get_global_rank" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="homura.get_local_rank">
<code class="sig-prename descclassname">homura.</code><code class="sig-name descname">get_local_rank</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="_modules/homura/utils/environment.html#get_local_rank"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.get_local_rank" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="homura.get_world_size">
<code class="sig-prename descclassname">homura.</code><code class="sig-name descname">get_world_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="_modules/homura/utils/environment.html#get_world_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.get_world_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="homura.get_num_nodes">
<code class="sig-prename descclassname">homura.</code><code class="sig-name descname">get_num_nodes</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="_modules/homura/utils/environment.html#get_num_nodes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#homura.get_num_nodes" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="homura.callbacks.html" class="btn btn-neutral float-right" title="homura.callbacks package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral float-left" title="Indices and tables" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Ryuichiro Hataya

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>